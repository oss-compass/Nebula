import logging
import json
import re
from typing import Dict, List, Any, Optional, Tuple, Set
import numpy as np
from collections import defaultdict
from dataclasses import dataclass
import concurrent.futures
from threading import Lock

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    logging.warning("sentence-transformers not available, semantic search will be disabled")

from .vector_embedding import CodeVectorizer, EmbeddingConfig, CodeEmbedding
from .sync_indexer import SyncSemanticIndexer, SyncIndexerConfig
from .single_repo import SingleRepoSearch, SearchQuery, SearchResult, SearchConfig

logger = logging.getLogger(__name__)

@dataclass
class MultiRepoSearchConfig:
    """å¤šåº“æœç´¢é…ç½®"""
    embedding_model: str = "all-MiniLM-L6-v2"
    similarity_threshold: float = 0.7
    max_results_per_repo: int = 20
    max_total_results: int = 100
    enable_parallel_search: bool = True
    max_workers: int = 4
    enable_cache: bool = True
    cross_repo_similarity_threshold: float = 0.8

@dataclass
class RepoConfig:
    """ä»“åº“é…ç½®"""
    repo_name: str
    neo4j_uri: str
    neo4j_user: str
    neo4j_password: str
    neo4j_database: str
    description: Optional[str] = None
    tags: Optional[List[str]] = None

@dataclass
class CrossRepoResult:
    """è·¨åº“æœç´¢ç»“æœ"""
    repo_name: str
    results: List[SearchResult]
    repo_similarity_score: float
    total_matches: int

@dataclass
class MultiRepoSearchResult:
    """å¤šåº“æœç´¢ç»“æœ"""
    query: str
    total_repos_searched: int
    total_results: int
    cross_repo_results: List[CrossRepoResult]
    global_similarity_score: float
    search_timestamp: str

class MultiRepoSearch:
    """å¤šåº“è¯­ä¹‰æœç´¢å™?""
    
    def __init__(self, 
                 repo_configs: List[RepoConfig],
                 config: Optional[MultiRepoSearchConfig] = None):
        """
        åˆå§‹åŒ–å¤šåº“æœç´¢å™¨
        
        Args:
            repo_configs: ä»“åº“é…ç½®åˆ—è¡¨
            config: å¤šåº“æœç´¢é…ç½®
        """
        self.config = config or MultiRepoSearchConfig()
        self.repo_configs = repo_configs
        self.repo_searchers = {}
        self.search_cache = {}
        self.search_history = []
        self.cache_lock = Lock()
        
        # åˆå§‹åŒ–å„ä¸ªä»“åº“çš„æœç´¢å™?
        self._init_repo_searchers()
        
        # åˆå§‹åŒ–å…¨å±€å‘é‡åŒ–å™¨
        self.global_vectorizer = None
        self._init_global_vectorizer()
        
        logger.info(f"å¤šåº“æœç´¢å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ”¯æŒ?{len(self.repo_configs)} ä¸ªä»“åº?)
    
    def _init_repo_searchers(self):
        """åˆå§‹åŒ–å„ä¸ªä»“åº“çš„æœç´¢å™?""
        for repo_config in self.repo_configs:
            try:
                search_config = SearchConfig(
                    embedding_model=self.config.embedding_model,
                    similarity_threshold=self.config.similarity_threshold,
                    max_results=self.config.max_results_per_repo
                )
                
                searcher = SingleRepoSearch(
                    neo4j_uri=repo_config.neo4j_uri,
                    neo4j_user=repo_config.neo4j_user,
                    neo4j_password=repo_config.neo4j_password,
                    neo4j_database=repo_config.neo4j_database,
                    config=search_config
                )
                
                self.repo_searchers[repo_config.repo_name] = searcher
                logger.info(f"ä»“åº“æœç´¢å™¨åˆå§‹åŒ–æˆåŠŸ: {repo_config.repo_name}")
                
            except Exception as e:
                logger.error(f"ä»“åº“æœç´¢å™¨åˆå§‹åŒ–å¤±è´¥ {repo_config.repo_name}: {e}")
    
    def _init_global_vectorizer(self):
        """åˆå§‹åŒ–å…¨å±€å‘é‡åŒ–å™¨"""
        try:
            embedding_config = EmbeddingConfig(
                model_name=self.config.embedding_model,
                device="cpu"
            )
            self.global_vectorizer = CodeVectorizer(embedding_config)
            logger.info(f"å…¨å±€å‘é‡åŒ–å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.config.embedding_model}")
        except Exception as e:
            logger.error(f"å…¨å±€å‘é‡åŒ–å™¨åˆå§‹åŒ–å¤±è´? {e}")
            self.global_vectorizer = None
    
    def search_across_repos(self, 
                           query: str,
                           search_type: str = "hybrid",
                           similarity_threshold: float = None,
                           target_repos: Optional[List[str]] = None,
                           enable_cross_repo_analysis: bool = True) -> MultiRepoSearchResult:
        """
        è·¨åº“æœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            search_type: æœç´¢ç±»å‹
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€?
            target_repos: ç›®æ ‡ä»“åº“åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæœç´¢æ‰€æœ‰ä»“åº?
            enable_cross_repo_analysis: æ˜¯å¦å¯ç”¨è·¨åº“åˆ†æ
            
        Returns:
            å¤šåº“æœç´¢ç»“æœ
        """
        logger.info(f"æ‰§è¡Œè·¨åº“æœç´¢: {query}")
        
        # æ£€æŸ¥ç¼“å­?
        cache_key = self._get_cache_key(query, search_type, target_repos)
        if self.config.enable_cache:
            with self.cache_lock:
                if cache_key in self.search_cache:
                    logger.info("è¿”å›ç¼“å­˜ç»“æœ")
                    return self.search_cache[cache_key]
        
        # ç¡®å®šæœç´¢çš„ä»“åº?
        repos_to_search = target_repos or list(self.repo_searchers.keys())
        
        # æ‰§è¡Œå¹¶è¡Œæœç´¢
        cross_repo_results = []
        if self.config.enable_parallel_search:
            cross_repo_results = self._parallel_search(query, search_type, similarity_threshold, repos_to_search)
        else:
            cross_repo_results = self._sequential_search(query, search_type, similarity_threshold, repos_to_search)
        
        # è·¨åº“åˆ†æ
        if enable_cross_repo_analysis:
            cross_repo_results = self._analyze_cross_repo_similarity(cross_repo_results, query)
        
        # è®¡ç®—å…¨å±€ç›¸ä¼¼åº¦åˆ†æ•?
        global_similarity_score = self._calculate_global_similarity(cross_repo_results)
        
        # æ„å»ºç»“æœ
        result = MultiRepoSearchResult(
            query=query,
            total_repos_searched=len(repos_to_search),
            total_results=sum(len(crr.results) for crr in cross_repo_results),
            cross_repo_results=cross_repo_results,
            global_similarity_score=global_similarity_score,
            search_timestamp=json.dumps({"timestamp": "now"})
        )
        
        # ç¼“å­˜ç»“æœ
        if self.config.enable_cache:
            with self.cache_lock:
                self.search_cache[cache_key] = result
        
        # è®°å½•æœç´¢å†å²
        self._record_search(query, result)
        
        return result
    
    def _parallel_search(self, 
                        query: str, 
                        search_type: str, 
                        similarity_threshold: float,
                        repos_to_search: List[str]) -> List[CrossRepoResult]:
        """å¹¶è¡Œæœç´¢å¤šä¸ªä»“åº“"""
        cross_repo_results = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.config.max_workers) as executor:
            # æäº¤æœç´¢ä»»åŠ¡
            future_to_repo = {}
            for repo_name in repos_to_search:
                if repo_name in self.repo_searchers:
                    future = executor.submit(
                        self._search_single_repo,
                        repo_name,
                        query,
                        search_type,
                        similarity_threshold
                    )
                    future_to_repo[future] = repo_name
            
            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(future_to_repo):
                repo_name = future_to_repo[future]
                try:
                    results = future.result()
                    if results:
                        cross_repo_result = CrossRepoResult(
                            repo_name=repo_name,
                            results=results,
                            repo_similarity_score=0.0,  # å°†åœ¨åç»­åˆ†æä¸­è®¡ç®?
                            total_matches=len(results)
                        )
                        cross_repo_results.append(cross_repo_result)
                except Exception as e:
                    logger.error(f"ä»“åº“ {repo_name} æœç´¢å¤±è´¥: {e}")
        
        return cross_repo_results
    
    def _sequential_search(self, 
                          query: str, 
                          search_type: str, 
                          similarity_threshold: float,
                          repos_to_search: List[str]) -> List[CrossRepoResult]:
        """é¡ºåºæœç´¢å¤šä¸ªä»“åº“"""
        cross_repo_results = []
        
        for repo_name in repos_to_search:
            if repo_name in self.repo_searchers:
                try:
                    results = self._search_single_repo(
                        repo_name, query, search_type, similarity_threshold
                    )
                    if results:
                        cross_repo_result = CrossRepoResult(
                            repo_name=repo_name,
                            results=results,
                            repo_similarity_score=0.0,  # å°†åœ¨åç»­åˆ†æä¸­è®¡ç®?
                            total_matches=len(results)
                        )
                        cross_repo_results.append(cross_repo_result)
                except Exception as e:
                    logger.error(f"ä»“åº“ {repo_name} æœç´¢å¤±è´¥: {e}")
        
        return cross_repo_results
    
    def _search_single_repo(self, 
                           repo_name: str, 
                           query: str, 
                           search_type: str,
                           similarity_threshold: float) -> List[SearchResult]:
        """æœç´¢å•ä¸ªä»“åº“"""
        searcher = self.repo_searchers[repo_name]
        
        search_query = SearchQuery(
            query=query,
            query_type=search_type,
            top_k=self.config.max_results_per_repo,
            threshold=similarity_threshold or self.config.similarity_threshold
        )
        
        return searcher.search(search_query)
    
    def _analyze_cross_repo_similarity(self, 
                                     cross_repo_results: List[CrossRepoResult],
                                     query: str) -> List[CrossRepoResult]:
        """åˆ†æè·¨åº“ç›¸ä¼¼æ€?""
        if not self.global_vectorizer:
            logger.warning("å…¨å±€å‘é‡åŒ–å™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡è·¨åº“åˆ†æ?)
            return cross_repo_results
        
        try:
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_embedding = self.global_vectorizer.embed_text(query)
            
            # ä¸ºæ¯ä¸ªä»“åº“è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
            for cross_repo_result in cross_repo_results:
                if cross_repo_result.results:
                    # è®¡ç®—ä»“åº“çº§åˆ«çš„ç›¸ä¼¼åº¦åˆ†æ•°
                    repo_similarity_scores = []
                    for result in cross_repo_result.results:
                        if hasattr(result.code_embedding, 'embedding') and result.code_embedding.embedding:
                            similarity = self._calculate_similarity(
                                query_embedding, result.code_embedding.embedding
                            )
                            repo_similarity_scores.append(similarity)
                    
                    if repo_similarity_scores:
                        cross_repo_result.repo_similarity_score = np.mean(repo_similarity_scores)
                    else:
                        cross_repo_result.repo_similarity_score = 0.0
            
            # æŒ‰ä»“åº“ç›¸ä¼¼åº¦åˆ†æ•°æ’åº
            cross_repo_results.sort(key=lambda x: x.repo_similarity_score, reverse=True)
            
            return cross_repo_results
            
        except Exception as e:
            logger.error(f"è·¨åº“ç›¸ä¼¼æ€§åˆ†æå¤±è´? {e}")
            return cross_repo_results
    
    def _calculate_global_similarity(self, cross_repo_results: List[CrossRepoResult]) -> float:
        """è®¡ç®—å…¨å±€ç›¸ä¼¼åº¦åˆ†æ•?""
        if not cross_repo_results:
            return 0.0
        
        # è®¡ç®—æ‰€æœ‰ä»“åº“ç›¸ä¼¼åº¦åˆ†æ•°çš„åŠ æƒå¹³å?
        total_weight = 0
        weighted_sum = 0
        
        for cross_repo_result in cross_repo_results:
            weight = cross_repo_result.total_matches
            weighted_sum += cross_repo_result.repo_similarity_score * weight
            total_weight += weight
        
        if total_weight == 0:
            return 0.0
        
        return weighted_sum / total_weight
    
    def find_similar_apis_across_repos(self, 
                                     api_name: str,
                                     similarity_threshold: float = None,
                                     target_repos: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        è·¨åº“æŸ¥æ‰¾ç›¸ä¼¼API
        
        Args:
            api_name: APIåç§°
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€?
            target_repos: ç›®æ ‡ä»“åº“åˆ—è¡¨
            
        Returns:
            ç›¸ä¼¼APIåˆ†æç»“æœ
        """
        logger.info(f"è·¨åº“æŸ¥æ‰¾ç›¸ä¼¼API: {api_name}")
        
        # æ„å»ºæœç´¢æŸ¥è¯¢
        query = f"API similar to {api_name}"
        
        # æ‰§è¡Œè·¨åº“æœç´¢
        search_result = self.search_across_repos(
            query=query,
            search_type="semantic",
            similarity_threshold=similarity_threshold or self.config.cross_repo_similarity_threshold,
            target_repos=target_repos,
            enable_cross_repo_analysis=True
        )
        
        # åˆ†æç»“æœ
        api_analysis = {
            "target_api": api_name,
            "total_repos_analyzed": search_result.total_repos_searched,
            "total_similar_apis": search_result.total_results,
            "global_similarity_score": search_result.global_similarity_score,
            "repo_analysis": []
        }
        
        for cross_repo_result in search_result.cross_repo_results:
            repo_analysis = {
                "repo_name": cross_repo_result.repo_name,
                "similarity_score": cross_repo_result.repo_similarity_score,
                "api_count": cross_repo_result.total_matches,
                "similar_apis": []
            }
            
            for result in cross_repo_result.results:
                api_info = {
                    "name": getattr(result.code_embedding, 'name', 'Unknown'),
                    "similarity_score": result.similarity_score,
                    "content": result.code_embedding.content[:200] + "...",
                    "file_path": getattr(result.code_embedding, 'file_path', 'Unknown'),
                    "explanation": result.explanation
                }
                repo_analysis["similar_apis"].append(api_info)
            
            api_analysis["repo_analysis"].append(repo_analysis)
        
        return api_analysis
    
    def analyze_api_usage_patterns(self, 
                                 api_name: str,
                                 target_repos: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        åˆ†æAPIä½¿ç”¨æ¨¡å¼
        
        Args:
            api_name: APIåç§°
            target_repos: ç›®æ ‡ä»“åº“åˆ—è¡¨
            
        Returns:
            APIä½¿ç”¨æ¨¡å¼åˆ†æç»“æœ
        """
        logger.info(f"åˆ†æAPIä½¿ç”¨æ¨¡å¼: {api_name}")
        
        usage_patterns = {
            "api_name": api_name,
            "total_repos_analyzed": 0,
            "usage_statistics": {},
            "repo_usage_patterns": []
        }
        
        repos_to_analyze = target_repos or list(self.repo_searchers.keys())
        usage_patterns["total_repos_analyzed"] = len(repos_to_analyze)
        
        for repo_name in repos_to_analyze:
            if repo_name in self.repo_searchers:
                try:
                    searcher = self.repo_searchers[repo_name]
                    
                    # æœç´¢APIä½¿ç”¨
                    usage_results = searcher.search_by_natural_language(
                        query=f"usage of {api_name}",
                        limit=50,
                        search_type="keyword"
                    )
                    
                    if usage_results:
                        repo_pattern = {
                            "repo_name": repo_name,
                            "usage_count": len(usage_results),
                            "usage_examples": []
                        }
                        
                        for result in usage_results[:10]:  # åªå–å‰?0ä¸ªä¾‹å­?
                            usage_example = {
                                "function_name": result.get("name", "Unknown"),
                                "file_path": result.get("file_path", "Unknown"),
                                "content_preview": result.get("content", "")[:150] + "...",
                                "similarity_score": result.get("similarity_score", 0.0)
                            }
                            repo_pattern["usage_examples"].append(usage_example)
                        
                        usage_patterns["repo_usage_patterns"].append(repo_pattern)
                        
                        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                        if repo_name not in usage_patterns["usage_statistics"]:
                            usage_patterns["usage_statistics"][repo_name] = 0
                        usage_patterns["usage_statistics"][repo_name] += len(usage_results)
                
                except Exception as e:
                    logger.error(f"åˆ†æä»“åº“ {repo_name} çš„APIä½¿ç”¨æ¨¡å¼å¤±è´¥: {e}")
        
        return usage_patterns
    
    def recommend_similar_repos(self, 
                              query: str,
                              top_k: int = 5) -> List[Dict[str, Any]]:
        """
        æ¨èç›¸ä¼¼ä»“åº“
        
        Args:
            query: æŸ¥è¯¢æè¿°
            top_k: è¿”å›çš„ä»“åº“æ•°é‡?
            
        Returns:
            ç›¸ä¼¼ä»“åº“æ¨èåˆ—è¡¨
        """
        logger.info(f"æ¨èç›¸ä¼¼ä»“åº“: {query}")
        
        # æ‰§è¡Œè·¨åº“æœç´¢
        search_result = self.search_across_repos(
            query=query,
            search_type="hybrid",
            enable_cross_repo_analysis=True
        )
        
        # æ„å»ºæ¨èç»“æœ
        recommendations = []
        for cross_repo_result in search_result.cross_repo_results:
            if cross_repo_result.repo_similarity_score > 0.5:  # åªæ¨èç›¸ä¼¼åº¦è¾ƒé«˜çš„ä»“åº?
                recommendation = {
                    "repo_name": cross_repo_result.repo_name,
                    "similarity_score": cross_repo_result.repo_similarity_score,
                    "match_count": cross_repo_result.total_matches,
                    "description": self._get_repo_description(cross_repo_result.repo_name),
                    "tags": self._get_repo_tags(cross_repo_result.repo_name)
                }
                recommendations.append(recommendation)
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶é™åˆ¶æ•°é‡?
        recommendations.sort(key=lambda x: x["similarity_score"], reverse=True)
        return recommendations[:top_k]
    
    def _get_repo_description(self, repo_name: str) -> str:
        """è·å–ä»“åº“æè¿°"""
        for repo_config in self.repo_configs:
            if repo_config.repo_name == repo_name:
                return repo_config.description or f"Repository: {repo_name}"
        return f"Repository: {repo_name}"
    
    def _get_repo_tags(self, repo_name: str) -> List[str]:
        """è·å–ä»“åº“æ ‡ç­¾"""
        for repo_config in self.repo_configs:
            if repo_config.repo_name == repo_name:
                return repo_config.tags or []
        return []
    
    def _calculate_similarity(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:
        """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ç›¸ä¼¼åº¦"""
        try:
            # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº?
            dot_product = np.dot(embedding1, embedding2)
            norm1 = np.linalg.norm(embedding1)
            norm2 = np.linalg.norm(embedding2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            similarity = dot_product / (norm1 * norm2)
            return float(similarity)
        except Exception as e:
            logger.error(f"è®¡ç®—ç›¸ä¼¼åº¦å¤±è´? {e}")
            return 0.0
    
    def _get_cache_key(self, query: str, search_type: str, target_repos: Optional[List[str]]) -> str:
        """ç”Ÿæˆç¼“å­˜é”?""
        import hashlib
        repos_str = json.dumps(sorted(target_repos or []), sort_keys=True)
        key_data = f"{query}_{search_type}_{repos_str}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def _record_search(self, query: str, result: MultiRepoSearchResult):
        """è®°å½•æœç´¢å†å²"""
        search_record = {
            "timestamp": json.dumps({"timestamp": "now"}),
            "query": query,
            "total_repos": result.total_repos_searched,
            "total_results": result.total_results,
            "global_similarity": result.global_similarity_score
        }
        self.search_history.append(search_record)
        
        # é™åˆ¶å†å²è®°å½•æ•°é‡
        if len(self.search_history) > 100:
            self.search_history = self.search_history[-100:]
    
    def get_search_history(self) -> List[Dict[str, Any]]:
        """è·å–æœç´¢å†å²"""
        return self.search_history.copy()
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        with self.cache_lock:
            self.search_cache.clear()
        logger.info("å¤šåº“æœç´¢ç¼“å­˜å·²æ¸…ç©?)
    
    def get_repo_statistics(self) -> Dict[str, Any]:
        """è·å–ä»“åº“ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_repos": len(self.repo_configs),
            "active_searchers": len(self.repo_searchers),
            "repo_details": []
        }
        
        for repo_config in self.repo_configs:
            repo_detail = {
                "repo_name": repo_config.repo_name,
                "description": repo_config.description,
                "tags": repo_config.tags,
                "searcher_available": repo_config.repo_name in self.repo_searchers
            }
            stats["repo_details"].append(repo_detail)
        
        return stats
    
    def close(self):
        """å…³é—­å¤šåº“æœç´¢å™?""
        for searcher in self.repo_searchers.values():
            searcher.close()
        logger.info("å¤šåº“æœç´¢å™¨å·²å…³é—­")

def create_multi_repo_search(repo_configs: List[RepoConfig],
                           config: MultiRepoSearchConfig = None) -> MultiRepoSearch:
    """åˆ›å»ºå¤šåº“æœç´¢å™¨å®ä¾?""
    return MultiRepoSearch(repo_configs, config)
