#!/usr/bin/env python3
"""
ä»£ç èšç±»å’Œç›¸ä¼¼æ€§åˆ†ææµ‹è¯•è„šæœ¬
ä¸“é—¨ç”¨äºæµ‹è¯•è¯­ä¹‰æœç´¢ç³»ç»Ÿä¸­çš„ä»£ç èšç±»ã€ç›¸ä¼¼æ€§åˆ†æã€é‡å¤ä»£ç æ£€æµ‹ç­‰åŠŸèƒ½
"""

import os
import sys
import json
import tempfile
import shutil
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_code_clustering():
    """æµ‹è¯•ä»£ç èšç±»åŠŸèƒ½"""
    print("ğŸ” Testing Code Clustering Functionality")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•ç›®å½•å’Œæ–‡ä»¶
    test_dir = tempfile.mkdtemp()
    
    # åˆ›å»ºå¤šä¸ªæµ‹è¯•æ–‡ä»¶ï¼ŒåŒ…å«ä¸åŒç±»å‹çš„å‡½æ•°
    test_files = {
        "search_algorithms.py": '''
def binary_search(arr, target):
    """Binary search in sorted array"""
    left, right = 0, len(arr) - 1
    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    return -1

def linear_search(arr, target):
    """Linear search in array"""
    for i, item in enumerate(arr):
        if item == target:
            return i
    return -1

def interpolation_search(arr, target):
    """Interpolation search in sorted array"""
    left, right = 0, len(arr) - 1
    while left <= right and arr[left] <= target <= arr[right]:
        pos = left + int(((target - arr[left]) * (right - left)) / (arr[right] - arr[left]))
        if arr[pos] == target:
            return pos
        elif arr[pos] < target:
            left = pos + 1
        else:
            right = pos - 1
    return -1
''',
        "math_functions.py": '''
def fibonacci(n):
    """Calculate nth Fibonacci number"""
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

def factorial(n):
    """Calculate factorial of n"""
    if n <= 1:
        return 1
    return n * factorial(n-1)

def power(base, exponent):
    """Calculate base raised to exponent"""
    if exponent == 0:
        return 1
    return base * power(base, exponent - 1)
''',
        "string_utils.py": '''
def reverse_string(s):
    """Reverse a string"""
    return s[::-1]

def is_palindrome(s):
    """Check if string is palindrome"""
    return s == s[::-1]

def count_vowels(s):
    """Count vowels in string"""
    vowels = 'aeiouAEIOU'
    return sum(1 for char in s if char in vowels)
''',
        "data_processing.py": '''
def filter_positive_numbers(numbers):
    """Filter positive numbers from list"""
    return [num for num in numbers if num > 0]

def map_double(numbers):
    """Double each number in list"""
    return [num * 2 for num in numbers]

def reduce_sum(numbers):
    """Sum all numbers in list"""
    return sum(numbers)
'''
    }
    
    # å†™å…¥æµ‹è¯•æ–‡ä»¶
    for filename, content in test_files.items():
        filepath = os.path.join(test_dir, filename)
        with open(filepath, 'w') as f:
            f.write(content)
    
    try:
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        print("1. Setting up indexer and searcher...")
        from sync_indexer import create_default_sync_config, SyncSemanticIndexer
        from semantic_search import create_advanced_searcher
        
        # åˆ›å»ºé…ç½®å’Œç´¢å¼•å™¨
        sync_config = create_default_sync_config(test_dir)
        indexer = SyncSemanticIndexer(sync_config)
        indexer.index_repository()
        
        # åˆ›å»ºé«˜çº§æœç´¢å™¨
        searcher = create_advanced_searcher(indexer)
        print("   âœ… Setup successful")
        
        # æµ‹è¯•èšç±»åŠŸèƒ½
        print("2. Testing function clustering...")
        try:
            clusters = searcher.cluster_similar_functions(n_clusters=3)
            print(f"   âœ… Clustering successful: found {len(clusters)} clusters")
            
            # æ˜¾ç¤ºèšç±»ç»“æœ
            for cluster_id, functions in clusters.items():
                print(f"   Cluster {cluster_id}: {len(functions)} functions")
                for func in functions[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    context = func.context or {}
                    print(f"     - {context.get('function_name', 'Unknown')} "
                          f"({context.get('file_path', 'Unknown')})")
                if len(functions) > 3:
                    print(f"     ... and {len(functions) - 3} more")
                print()
        except Exception as e:
            print(f"   âŒ Clustering error: {e}")
            return False
        
        # æµ‹è¯•ç›¸ä¼¼æ€§åˆ†æ
        print("3. Testing similarity analysis...")
        try:
            # è·å–ä¸€ä¸ªå‡½æ•°ä½œä¸ºç¤ºä¾‹
            embeddings_list = list(indexer.embedding_manager.embeddings_index.values())
            if embeddings_list:
                example_function = embeddings_list[0]
                recommendations = searcher.get_recommendations(example_function, top_k=3)
                print(f"   âœ… Similarity analysis successful: found {len(recommendations)} similar functions")
                
                context = example_function.metadata
                print(f"   Example function: {context.get('name', 'Unknown')}")
                print("   Similar functions:")
                for rec in recommendations:
                    rec_context = rec.context or {}
                    print(f"     - {rec_context.get('function_name', 'Unknown')} "
                          f"(similarity: {rec.similarity:.4f})")
            else:
                print("   âš ï¸ No functions found for similarity analysis")
        except Exception as e:
            print(f"   âŒ Similarity analysis error: {e}")
            return False
        
        # æµ‹è¯•é‡å¤ä»£ç æ£€æµ‹
        print("4. Testing duplicate code detection...")
        try:
            duplicates = searcher.find_duplicate_code(threshold=0.8)
            print(f"   âœ… Duplicate detection successful: found {len(duplicates)} duplicate groups")
            
            for i, group in enumerate(duplicates[:2]):  # åªæ˜¾ç¤ºå‰2ç»„
                print(f"   Duplicate group {i+1}: {len(group)} functions")
                for func in group:
                    context = func.context or {}
                    print(f"     - {context.get('function_name', 'Unknown')} "
                          f"({context.get('file_path', 'Unknown')})")
                print()
        except Exception as e:
            print(f"   âŒ Duplicate detection error: {e}")
            return False
        
        # æµ‹è¯•å¤æ‚åº¦åˆ†æ
        print("5. Testing complexity analysis...")
        try:
            complexity_analysis = searcher.get_code_complexity_analysis()
            print("   âœ… Complexity analysis successful")
            print(f"   Total functions: {complexity_analysis.get('total_functions', 0)}")
            print(f"   Average complexity: {complexity_analysis.get('average_complexity', 0):.2f}")
            print(f"   Max complexity: {complexity_analysis.get('max_complexity', 0)}")
            print(f"   Function types: {complexity_analysis.get('function_type_distribution', {})}")
        except Exception as e:
            print(f"   âŒ Complexity analysis error: {e}")
            return False
        
        # æ¸…ç†
        indexer.close()
        
        print("\nğŸ‰ Code clustering and analysis tests passed successfully!")
        return True
        
    except Exception as e:
        print(f"\nâŒ Test failed with error: {e}")
        return False
    
    finally:
        # æ¸…ç†æµ‹è¯•ç›®å½•
        shutil.rmtree(test_dir)


def test_attrs_index_clustering():
    """ä½¿ç”¨attrs_index.jsonæµ‹è¯•èšç±»åŠŸèƒ½"""
    print("\nğŸ“Š Testing Clustering with attrs_index.json")
    print("=" * 60)
    
    # æ£€æŸ¥attrs_index.jsonæ˜¯å¦å­˜åœ¨
    attrs_index_path = "attrs_index.json"
    if not os.path.exists(attrs_index_path):
        print(f"âŒ attrs_index.json not found at {attrs_index_path}")
        print("Please make sure the index file exists in the current directory")
        return False
    
    try:
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        print("1. Loading attrs index...")
        from sync_indexer import create_default_sync_config, SyncSemanticIndexer
        from semantic_search import create_advanced_searcher
        
        # åˆ›å»ºé…ç½®ï¼ˆä½¿ç”¨attrsé¡¹ç›®è·¯å¾„ï¼‰
        attrs_repo_path = "F:\\aaa_school\\OSPP\\osscompass\\target_project\\attrs"
        if not os.path.exists(attrs_repo_path):
            print(f"âŒ Attrs repository not found at {attrs_repo_path}")
            print("Please update the path in the script")
            return False
        
        sync_config = create_default_sync_config(attrs_repo_path)
        # ä½¿ç”¨TF-IDFæ¨¡å‹é¿å…ç½‘ç»œè¿æ¥é—®é¢˜
        sync_config.embedding_config.model_type = "tfidf"
        indexer = SyncSemanticIndexer(sync_config)
        
        # åŠ è½½ç°æœ‰ç´¢å¼•
        indexer.load_index(attrs_index_path)
        print("   âœ… Index loaded successfully")
        
        # åˆ›å»ºé«˜çº§æœç´¢å™¨
        searcher = create_advanced_searcher(indexer)
        print("   âœ… Searcher created successfully")
        
        # è·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
        stats = indexer.get_stats()
        print(f"   Index contains {stats.get('total_functions', 0)} functions")
        
        # æµ‹è¯•èšç±»åŠŸèƒ½
        print("2. Testing function clustering on attrs codebase...")
        try:
            # ä½¿ç”¨æ›´å¤šçš„èšç±»æ•°é‡ï¼Œå› ä¸ºattrsæ˜¯ä¸€ä¸ªè¾ƒå¤§çš„é¡¹ç›®
            clusters = searcher.cluster_similar_functions(n_clusters=10)
            print(f"   âœ… Clustering successful: found {len(clusters)} clusters")
            
            # æ˜¾ç¤ºèšç±»ç»“æœ
            print("\n   Clustering Results:")
            print("   " + "="*50)
            for cluster_id, functions in clusters.items():
                print(f"   Cluster {cluster_id}: {len(functions)} functions")
                
                # æ˜¾ç¤ºæ¯ä¸ªèšç±»ä¸­çš„å‰å‡ ä¸ªå‡½æ•°
                for i, func in enumerate(functions[:5]):  # æ˜¾ç¤ºå‰5ä¸ª
                    context = func.context or {}
                    func_name = context.get('function_name', 'Unknown')
                    file_path = context.get('file_path', 'Unknown')
                    # åªæ˜¾ç¤ºæ–‡ä»¶åï¼Œä¸æ˜¾ç¤ºå®Œæ•´è·¯å¾„
                    file_name = os.path.basename(file_path) if file_path != 'Unknown' else 'Unknown'
                    print(f"     {i+1}. {func_name} ({file_name})")
                
                if len(functions) > 5:
                    print(f"     ... and {len(functions) - 5} more functions")
                print()
        except Exception as e:
            print(f"   âŒ Clustering error: {e}")
            return False
        
        # æµ‹è¯•ç›¸ä¼¼æ€§åˆ†æ
        print("3. Testing similarity analysis on attrs functions...")
        try:
            # æµ‹è¯•æŒ‡å®šçš„ä¸‰ä¸ªå‡½æ•°
            test_functions = ["attrib (_make.py)", "optional (converters.py)", "convert (setters.py)"]
            
            for func_name in test_functions:
                print(f"\n   Function: {func_name}")
                try:
                    # é€šè¿‡å‡½æ•°ååœ¨ç´¢å¼•ä¸­æŸ¥æ‰¾å¯¹åº”çš„embedding
                    target_embedding = None
                    for embedding in indexer.embedding_manager.embeddings_index.values():
                        context = embedding.metadata
                        func_name_from_meta = context.get('name', '')
                        file_path = context.get('file_path', '')
                        file_name = os.path.basename(file_path) if file_path else ''
                        
                        # æ£€æŸ¥æ˜¯å¦åŒ¹é…å‡½æ•°åå’Œæ–‡ä»¶å
                        if func_name_from_meta in func_name and file_name in func_name:
                            target_embedding = embedding
                            break
                    
                    if target_embedding:
                        # ä½¿ç”¨get_recommendationsæ–¹æ³•æŸ¥æ‰¾ç›¸ä¼¼å‡½æ•°
                        recommendations = searcher.get_recommendations(target_embedding, top_k=5)
                        if recommendations:
                            print(f"   Similar functions ({len(recommendations)} found):")
                            for i, rec in enumerate(recommendations, 1):
                                # ä»embeddingçš„metadataä¸­è·å–ä¿¡æ¯
                                rec_metadata = rec.embedding.metadata
                                
                                # æå–å‡½æ•°åå’Œæ–‡ä»¶è·¯å¾„
                                rec_name = rec_metadata.get('name', 'Unknown')
                                rec_file_path = rec_metadata.get('filepath', 'Unknown')  # æ³¨æ„ï¼šmetadataä¸­æ˜¯'filepath'ä¸æ˜¯'file_path'
                                rec_file = os.path.basename(rec_file_path) if rec_file_path != 'Unknown' else 'Unknown'
                                
                                print(f"     {i}. {rec_name} ({rec_file}) - similarity: {rec.similarity:.4f}")
                        else:
                            print("   Similar functions (0 found):")
                    else:
                        print(f"   âŒ Function {func_name} not found in index")
                except Exception as e:
                    print(f"   âŒ Error finding similar functions for {func_name}: {e}")
        except Exception as e:
            print(f"   âŒ Similarity analysis error: {e}")
            return False
        
        # æµ‹è¯•é‡å¤ä»£ç æ£€æµ‹
        print("4. Testing duplicate code detection on attrs codebase...")
        try:
            # ä½¿ç”¨è¾ƒé«˜çš„é˜ˆå€¼ï¼Œå› ä¸ºattrsæ˜¯ç»è¿‡è‰¯å¥½ç»´æŠ¤çš„é¡¹ç›®
            duplicates = searcher.find_duplicate_code(threshold=0.9)
            print(f"   âœ… Duplicate detection successful: found {len(duplicates)} duplicate groups")
            
            if duplicates:
                print("   Duplicate groups found:")
                for i, group in enumerate(duplicates[:3]):  # åªæ˜¾ç¤ºå‰3ç»„
                    print(f"   Group {i+1}: {len(group)} functions")
                    for func in group:
                        context = func.context or {}
                        func_name = context.get('function_name', 'Unknown')
                        file_name = os.path.basename(context.get('file_path', 'Unknown'))
                        print(f"     - {func_name} ({file_name})")
                    print()
            else:
                print("   No significant duplicates found (good code quality!)")
        except Exception as e:
            print(f"   âŒ Duplicate detection error: {e}")
            return False
        
        # æµ‹è¯•å¤æ‚åº¦åˆ†æ
        print("5. Testing complexity analysis on attrs codebase...")
        try:
            complexity_analysis = searcher.get_code_complexity_analysis()
            print("   âœ… Complexity analysis successful")
            print(f"   Total functions: {complexity_analysis.get('total_functions', 0)}")
            print(f"   Average complexity: {complexity_analysis.get('average_complexity', 0):.2f}")
            print(f"   Max complexity: {complexity_analysis.get('max_complexity', 0)}")
            print(f"   Min complexity: {complexity_analysis.get('min_complexity', 0)}")
            print(f"   Std complexity: {complexity_analysis.get('std_complexity', 0):.2f}")
            
            # æ˜¾ç¤ºå¤æ‚åº¦åˆ†å¸ƒ
            distribution = complexity_analysis.get('complexity_distribution', {})
            print("   Complexity distribution:")
            print(f"     Low (0-2): {distribution.get('low', 0)} functions")
            print(f"     Medium (2-5): {distribution.get('medium', 0)} functions")
            print(f"     High (5-10): {distribution.get('high', 0)} functions")
            print(f"     Very High (10+): {distribution.get('very_high', 0)} functions")
            
            # æ˜¾ç¤ºå‡½æ•°ç±»å‹åˆ†å¸ƒ
            func_types = complexity_analysis.get('function_type_distribution', {})
            if func_types:
                print("   Function types:")
                for func_type, count in func_types.items():
                    print(f"     {func_type}: {count} functions")
        except Exception as e:
            print(f"   âŒ Complexity analysis error: {e}")
            return False
        
        # æ¸…ç†
        indexer.close()
        
        print("\nğŸ‰ Attrs index clustering and analysis tests passed successfully!")
        return True
        
    except Exception as e:
        print(f"\nâŒ Attrs index test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_advanced_search_features():
    """æµ‹è¯•é«˜çº§æœç´¢åŠŸèƒ½"""
    print("\nğŸ”¬ Testing Advanced Search Features")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•ç›®å½•å’Œæ–‡ä»¶
    test_dir = tempfile.mkdtemp()
    test_file = os.path.join(test_dir, "test.py")
    
    test_code = '''
def calculate_fibonacci(n):
    """Calculate the nth Fibonacci number using recursion"""
    if n <= 1:
        return n
    return calculate_fibonacci(n-1) + calculate_fibonacci(n-2)

def fibonacci_iterative(n):
    """Calculate the nth Fibonacci number using iteration"""
    if n <= 1:
        return n
    a, b = 0, 1
    for _ in range(2, n + 1):
        a, b = b, a + b
    return b

def binary_search(arr, target):
    """Binary search in sorted array"""
    left, right = 0, len(arr) - 1
    while left <= right:
        mid = (left + right) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
    return -1

def linear_search(arr, target):
    """Linear search in array"""
    for i, item in enumerate(arr):
        if item == target:
            return i
    return -1

class SearchAlgorithms:
    """Collection of search algorithms"""
    
    def __init__(self):
        self.algorithms = {
            'binary': binary_search,
            'linear': linear_search
        }
    
    def search(self, arr, target, algorithm='binary'):
        """Search using specified algorithm"""
        if algorithm in self.algorithms:
            return self.algorithms[algorithm](arr, target)
        else:
            raise ValueError(f"Unknown algorithm: {algorithm}")
'''
    
    with open(test_file, 'w') as f:
        f.write(test_code)
    
    try:
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        print("1. Setting up advanced search...")
        from sync_indexer import create_default_sync_config, SyncSemanticIndexer
        from semantic_search import create_advanced_searcher, SearchQuery
        
        # åˆ›å»ºé…ç½®å’Œç´¢å¼•å™¨
        sync_config = create_default_sync_config(test_dir)
        indexer = SyncSemanticIndexer(sync_config)
        indexer.index_repository()
        
        # åˆ›å»ºé«˜çº§æœç´¢å™¨
        searcher = create_advanced_searcher(indexer)
        print("   âœ… Setup successful")
        
        # æµ‹è¯•åŸºäºç¤ºä¾‹çš„æœç´¢
        print("2. Testing example-based search...")
        try:
            example_code = "def search(arr, target):\n    for i, item in enumerate(arr):\n        if item == target:\n            return i\n    return -1"
            example_results = searcher.search_by_example(example_code, top_k=3)
            print(f"   âœ… Example-based search successful: found {len(example_results)} results")
            
            for i, result in enumerate(example_results, 1):
                context = result.context or {}
                print(f"     {i}. {context.get('function_name', 'Unknown')} "
                      f"(similarity: {result.similarity:.4f})")
        except Exception as e:
            print(f"   âŒ Example-based search error: {e}")
            return False
        
        # æµ‹è¯•åŸºäºå‡½æ•°ç­¾åçš„æœç´¢
        print("3. Testing function signature search...")
        try:
            signature_results = searcher.search_by_function_signature(
                "search", 
                parameters=["arr", "target"], 
                top_k=3
            )
            print(f"   âœ… Function signature search successful: found {len(signature_results)} results")
            
            for i, result in enumerate(signature_results, 1):
                context = result.context or {}
                print(f"     {i}. {context.get('function_name', 'Unknown')} "
                      f"(similarity: {result.similarity:.4f})")
        except Exception as e:
            print(f"   âŒ Function signature search error: {e}")
            return False
        
        # æµ‹è¯•æœç´¢å»ºè®®
        print("4. Testing search suggestions...")
        try:
            suggestions = searcher.get_search_suggestions("fib", limit=5)
            print(f"   âœ… Search suggestions successful: found {len(suggestions)} suggestions")
            print(f"   Suggestions: {suggestions}")
        except Exception as e:
            print(f"   âŒ Search suggestions error: {e}")
            return False
        
        # æµ‹è¯•æœç´¢åˆ†æ
        print("5. Testing search analytics...")
        try:
            # å…ˆæ‰§è¡Œä¸€äº›æœç´¢æ¥ç”Ÿæˆå†å²
            queries = [
                SearchQuery("fibonacci calculation", "semantic", top_k=3),
                SearchQuery("search algorithm", "semantic", top_k=3),
                SearchQuery("binary search", "keyword", top_k=3)
            ]
            
            for query in queries:
                searcher.search(query)
            
            analytics = searcher.get_search_analytics()
            print("   âœ… Search analytics successful")
            print(f"   Total searches: {analytics.get('total_searches', 0)}")
            print(f"   Query types: {analytics.get('query_type_distribution', {})}")
            print(f"   Average result count: {analytics.get('average_result_count', 0):.2f}")
        except Exception as e:
            print(f"   âŒ Search analytics error: {e}")
            return False
        
        # æ¸…ç†
        indexer.close()
        
        print("\nğŸ‰ Advanced search features tests passed successfully!")
        return True
        
    except Exception as e:
        print(f"\nâŒ Advanced search test failed with error: {e}")
        return False
    
    finally:
        # æ¸…ç†æµ‹è¯•ç›®å½•
        shutil.rmtree(test_dir)


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ Code Clustering and Similarity Analysis Test Suite")
    print("=" * 80)
    
    all_passed = True
    
    # è¿è¡ŒåŸºæœ¬èšç±»æµ‹è¯•
    if not test_code_clustering():
        all_passed = False
    
    # è¿è¡Œattrsç´¢å¼•èšç±»æµ‹è¯•
    if not test_attrs_index_clustering():
        all_passed = False
    
    # è¿è¡Œé«˜çº§æœç´¢åŠŸèƒ½æµ‹è¯•
    if not test_advanced_search_features():
        all_passed = False
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    if all_passed:
        print("ğŸ‰ All clustering and analysis tests passed!")
        print("\nAvailable clustering and analysis features:")
        print("1. Function clustering - Group similar functions together")
        print("2. Similarity analysis - Find similar functions to a given function")
        print("3. Duplicate code detection - Find duplicate or near-duplicate code")
        print("4. Complexity analysis - Analyze code complexity distribution")
        print("5. Example-based search - Search using code examples")
        print("6. Function signature search - Search by function signatures")
        print("7. Search suggestions - Get intelligent search suggestions")
        print("8. Search analytics - Analyze search patterns and performance")
        
        print("\nUsage examples:")
        print("# Test clustering on your own codebase:")
        print("python test_clustering_analysis.py")
        print("\n# Use with attrs_index.json:")
        print("python test_clustering_analysis.py --use-attrs-index")
    else:
        print("âŒ Some tests failed. Please check the error messages above.")
        print("\nTroubleshooting:")
        print("1. Make sure all required dependencies are installed")
        print("2. Check that attrs_index.json exists in the current directory")
        print("3. Verify the attrs repository path is correct")
    
    return 0 if all_passed else 1


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Test code clustering and similarity analysis")
    parser.add_argument("--use-attrs-index", action="store_true", 
                       help="Only test with attrs_index.json")
    parser.add_argument("--skip-attrs", action="store_true",
                       help="Skip attrs index tests")
    
    args = parser.parse_args()
    
    if args.use_attrs_index:
        # åªè¿è¡Œattrsç´¢å¼•æµ‹è¯•
        success = test_attrs_index_clustering()
        sys.exit(0 if success else 1)
    elif args.skip_attrs:
        # è·³è¿‡attrsæµ‹è¯•
        success = (test_code_clustering() and test_advanced_search_features())
        sys.exit(0 if success else 1)
    else:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        sys.exit(main())
