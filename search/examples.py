import logging
from typing import Dict, Any
from .main_interface import Neo4jSearchEngine

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def example_basic_queries():
    """åŸºç¡€æŸ¥è¯¢ç¤ºä¾‹"""
    print("=" * 50)
    print("åŸºç¡€æŸ¥è¯¢ç¤ºä¾‹")
    print("=" * 50)
    
    with Neo4jSearchEngine() as engine:
        # 1. æŸ¥æ‰¾APIè°ƒç”¨è€?
        print("\n1. æŸ¥æ‰¾APIè°ƒç”¨è€?")
        callers = engine.find_api_callers("process_data", max_depth=2)
        print(f"æ‰¾åˆ° {callers['total_callers']} ä¸ªè°ƒç”¨è€?)
        for caller in callers['direct_callers'][:3]:
            print(f"  - {caller['caller_name']} ({caller['caller_file']})")
        
        # 2. æŸ¥æ‰¾APIè¢«è°ƒç”¨è€?
        print("\n2. æŸ¥æ‰¾APIè¢«è°ƒç”¨è€?")
        callees = engine.find_api_callees("process_data", max_depth=2)
        print(f"æ‰¾åˆ° {callees['total_callees']} ä¸ªè¢«è°ƒç”¨è€?)
        for callee in callees['direct_callees'][:3]:
            print(f"  - {callee['callee_name']} ({callee['callee_file']})")
        
        # 3. è·å–ä¾èµ–æ¸…å•
        print("\n3. è·å–ä¾èµ–æ¸…å•:")
        deps = engine.get_dependency_list("process_data", include_transitive=True, max_depth=3)
        print(f"æ€»ä¾èµ–æ•°: {deps['total_dependencies']}")
        print(f"ç›´æ¥ä¾èµ–: {len(deps['direct_dependencies'])}")
        print(f"ä¼ é€’ä¾èµ? {len(deps['transitive_dependencies'])}")
        
        # 4. æ ¹æ®å‡½æ•°åæŸ¥æ‰?
        print("\n4. æ ¹æ®å‡½æ•°åæŸ¥æ‰?")
        functions = engine.find_function_by_name("process", exact_match=False)
        print(f"æ‰¾åˆ° {len(functions)} ä¸ªç›¸å…³å‡½æ•?)
        for func in functions[:3]:
            print(f"  - {func['name']} ({func['filepath']})")

def example_semantic_search():
    """è¯­ä¹‰æœç´¢ç¤ºä¾‹"""
    print("=" * 50)
    print("è¯­ä¹‰æœç´¢ç¤ºä¾‹")
    print("=" * 50)
    
    with Neo4jSearchEngine() as engine:
        # 1. è‡ªç„¶è¯­è¨€æœç´¢
        print("\n1. è‡ªç„¶è¯­è¨€æœç´¢:")
        results = engine.search_by_natural_language(
            "å¤„ç†æ•°æ®çš„å‡½æ•?, 
            limit=5, 
            search_type="hybrid"
        )
        print(f"æ‰¾åˆ° {len(results)} ä¸ªç»“æ?)
        for i, result in enumerate(results, 1):
            print(f"  {i}. {result['name']} - {result.get('similarity_score', 0):.3f}")
            if result.get('docstring_description'):
                print(f"     æè¿°: {result['docstring_description'][:100]}...")
        
        # 2. æŒ‰å¤æ‚åº¦æœç´¢
        print("\n2. æŒ‰å¤æ‚åº¦æœç´¢:")
        complex_funcs = engine.search_by_complexity(
            complexity_level="complex",
            min_complexity=10,
            limit=5
        )
        print(f"æ‰¾åˆ° {len(complex_funcs)} ä¸ªå¤æ‚å‡½æ•?)
        for func in complex_funcs[:3]:
            print(f"  - {func['name']} (å¤æ‚åº? {func.get('cyclomatic_complexity', 'N/A')})")
        
        # 3. æŸ¥æ‰¾ç›¸ä¼¼å‡½æ•°
        print("\n3. æŸ¥æ‰¾ç›¸ä¼¼å‡½æ•°:")
        similar_funcs = engine.search_similar_functions("process_data", limit=5)
        print(f"æ‰¾åˆ° {len(similar_funcs)} ä¸ªç›¸ä¼¼å‡½æ•?)
        for func in similar_funcs[:3]:
            print(f"  - {func['name']} (ç›¸ä¼¼åº? {func.get('similarity_score', 0):.3f})")

def example_graph_analysis():
    """å›¾åˆ†æç¤ºä¾?""
    print("=" * 50)
    print("å›¾åˆ†æç¤ºä¾?)
    print("=" * 50)
    
    with Neo4jSearchEngine() as engine:
        # 1. ä¸­å¿ƒæ€§åˆ†æ?
        print("\n1. ä¸­å¿ƒæ€§åˆ†æ?(PageRank):")
        centrality = engine.calculate_centrality("pagerank", top_k=10)
        print(f"åˆ†æ {centrality['total_nodes']} ä¸ªèŠ‚ç‚?)
        print("å‰?0ä¸ªæœ€é‡è¦çš„å‡½æ•?")
        for result in centrality['results'][:5]:
            print(f"  {result['rank']}. {result['node_name']} (åˆ†æ•°: {result['centrality_score']:.4f})")
        
        # 2. ç¤¾åŒºå‘ç°
        print("\n2. ç¤¾åŒºå‘ç°:")
        communities = engine.find_communities("louvain", min_community_size=3)
        print(f"å‘ç° {communities['total_communities']} ä¸ªç¤¾åŒ?)
        for i, community in enumerate(communities['communities'][:3], 1):
            print(f"  ç¤¾åŒº {i}: {community['size']} ä¸ªå‡½æ•?)
            for node in community['nodes'][:3]:
                print(f"    - {node['node_name']}")
        
        # 3. ç›¸ä¼¼åº¦çŸ©é˜?
        print("\n3. ç›¸ä¼¼åº¦çŸ©é˜?")
        function_names = ["process_data", "validate_input", "format_output"]
        similarity_matrix = engine.calculate_similarity_matrix(function_names, "structural")
        print("å‡½æ•°ç›¸ä¼¼åº¦çŸ©é˜?")
        for i, func1 in enumerate(function_names):
            for j, func2 in enumerate(function_names):
                score = similarity_matrix['similarity_matrix'][i][j]
                print(f"  {func1} vs {func2}: {score:.3f}")
        
        # 4. å›¾ç»Ÿè®¡ä¿¡æ?
        print("\n4. å›¾ç»Ÿè®¡ä¿¡æ?")
        stats = engine.get_graph_statistics()
        basic_stats = stats.get('basic_statistics', {})
        print(f"æ€»èŠ‚ç‚¹æ•°: {basic_stats.get('total_nodes', 0)}")
        print(f"æ€»è¾¹æ•? {basic_stats.get('total_edges', 0)}")
        print(f"å¹³å‡åº¦æ•°: {basic_stats.get('avg_degree', 0):.2f}")

def example_comprehensive_analysis():
    """ç»¼åˆåˆ†æç¤ºä¾‹"""
    print("=" * 50)
    print("ç»¼åˆåˆ†æç¤ºä¾‹")
    print("=" * 50)
    
    with Neo4jSearchEngine() as engine:
        # 1. å‡½æ•°é‡è¦æ€§åˆ†æ?
        print("\n1. å‡½æ•°é‡è¦æ€§åˆ†æ?")
        importance = engine.analyze_function_importance(
            "process_data",
            include_centrality=True,
            include_community=True,
            include_dependencies=True
        )
        
        if "error" not in importance:
            print(f"åˆ†æå‡½æ•°: {importance['function_name']}")
            
            # ä¸­å¿ƒæ€§æ’å?
            centrality = importance.get('centrality_analysis', {})
            if centrality and "function_rank" in centrality:
                print(f"ä¸­å¿ƒæ€§æ’å? {centrality['function_rank']}/{centrality['total_functions']}")
            
            # ç¤¾åŒºä¿¡æ¯
            community = importance.get('community_analysis', {})
            if community and "function_community" in community:
                func_community = community['function_community']
                if func_community:
                    print(f"æ‰€å±ç¤¾åŒ? ç¤¾åŒº {func_community['community_id']} (å¤§å°: {func_community['size']})")
            
            # ä¾èµ–ä¿¡æ¯
            deps = importance.get('dependency_analysis', {})
            if deps:
                print(f"æ€»ä¾èµ–æ•°: {deps['total_dependencies']}")
        else:
            print(f"åˆ†æå¤±è´¥: {importance['error']}")
        
        # 2. ç»¼åˆæœç´¢
        print("\n2. ç»¼åˆæœç´¢:")
        search_result = engine.comprehensive_search(
            "æ•°æ®å¤„ç†ç›¸å…³å‡½æ•°",
            search_type="hybrid",
            include_analysis=True,
            limit=5
        )
        
        print(f"æœç´¢æŸ¥è¯¢: {search_result['query']}")
        print(f"è¯­ä¹‰æœç´¢ç»“æœ: {search_result['total_semantic_results']} ä¸?)
        
        if search_result.get('importance_analysis'):
            print("é‡è¦æ€§åˆ†æç»“æ?")
            for analysis in search_result['importance_analysis']:
                func_name = analysis['function_name']
                components = analysis.get('analysis_components', [])
                print(f"  - {func_name}: {', '.join(components)}")

def example_export_results():
    """ç»“æœå¯¼å‡ºç¤ºä¾‹"""
    print("=" * 50)
    print("ç»“æœå¯¼å‡ºç¤ºä¾‹")
    print("=" * 50)
    
    with Neo4jSearchEngine() as engine:
        # æ‰§è¡Œæœç´¢
        results = engine.search_by_natural_language("æ•°æ®å¤„ç†", limit=5)
        
        # å¯¼å‡ºä¸ºJSON
        engine.export_results(results, "search_results.json", "json")
        print("ç»“æœå·²å¯¼å‡ºä¸ºJSONæ ¼å¼")
        
        # å¯¼å‡ºä¸ºMarkdown
        engine.export_results(results, "search_results.md", "markdown")
        print("ç»“æœå·²å¯¼å‡ºä¸ºMarkdownæ ¼å¼")

def main():
    """ä¸»å‡½æ•?- è¿è¡Œæ‰€æœ‰ç¤ºä¾?""
    print("Neo4jæœç´¢åŠŸèƒ½ç¤ºä¾‹")
    print("=" * 60)
    
    try:
        # åŸºç¡€æŸ¥è¯¢ç¤ºä¾‹
        example_basic_queries()
        
        # è¯­ä¹‰æœç´¢ç¤ºä¾‹
        example_semantic_search()
        
        # å›¾åˆ†æç¤ºä¾?
        example_graph_analysis()
        
        # ç»¼åˆåˆ†æç¤ºä¾‹
        example_comprehensive_analysis()
        
        # ç»“æœå¯¼å‡ºç¤ºä¾‹
        example_export_results()
        
        print("\n" + "=" * 60)
        print("æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {e}")
        print(f"é”™è¯¯: {e}")

if __name__ == "__main__":
    main()
