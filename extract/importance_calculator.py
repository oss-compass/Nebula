import math
from collections import defaultdict
from typing import Dict, List, Optional, Tuple
import numpy as np

try:
    import networkx as nx
    NETWORKX_AVAILABLE = True
except ImportError:
    NETWORKX_AVAILABLE = False

from .config import IMPORTANCE_THRESHOLDS


def calculate_function_importance(function_map: Dict, direct_calls: Dict, transitive_calls: Dict, transitive_paths: Dict, 
                                algorithm: str = "hybrid", pagerank_weight: float = 0.4, traditional_weight: float = 0.4, 
                                complexity_weight: float = 0.2) -> Dict:
    """
    è®¡ç®—å‡½æ•°é‡è¦åº?    
    æ”¯æŒä¸‰ç§ç®—æ³•ï¼?    1. "traditional": ä¼ ç»Ÿçš„å¤šç»´åº¦ç»Ÿè®¡ç®—æ³•
    2. "pagerank": åŸºäºPageRankçš„å›¾ç®—æ³•
    3. "hybrid": æ··åˆç®—æ³•ï¼Œç»“åˆPageRankå’Œä¼ ç»Ÿç®—æ³?    
    ä¼ ç»Ÿç®—æ³•è€ƒè™‘å› ç´ ï¼?    1. ç›´æ¥è°ƒç”¨é‡?(Direct Call Weight)
    2. ä¼ é€’è°ƒç”¨é‡ (Transitive Call Weight) 
    3. è°ƒç”¨æ·±åº¦å½±å“ (Depth Impact)
    4. æ¢çº½æ•ˆåº” (Hub Effect)
    5. è¢«è°ƒç”¨é¢‘ç?(Incoming Call Frequency)
    6. å¤æ‚åº¦è°ƒæ•?(Complexity Adjustment)
    
    PageRankç®—æ³•ï¼?    - åŸºäºè°ƒç”¨å›¾è®¡ç®—å…¨å±€é‡è¦æ€?    - è€ƒè™‘ä¼ é€’æ€§å½±å“?    - è¯†åˆ«å…³é”®æ¢çº½å‡½æ•°
    
    æ··åˆç®—æ³•ï¼?    æœ€ç»ˆé‡è¦åº¦ = Î± Ã— PageRankåˆ†æ•° + Î² Ã— ä¼ ç»Ÿåˆ†æ•° + Î³ Ã— å¤æ‚åº¦è°ƒæ•?    
    Args:
        function_map: å‡½æ•°ååˆ°å‡½æ•°ä¿¡æ¯çš„æ˜ å°?        direct_calls: ç›´æ¥è°ƒç”¨å…³ç³»
        transitive_calls: ä¼ é€’è°ƒç”¨å…³ç³?        transitive_paths: ä¼ é€’è°ƒç”¨è·¯å¾?        algorithm: ç®—æ³•ç±»å‹ ("traditional", "pagerank", "hybrid")
        pagerank_weight: PageRankæƒé‡ (æ··åˆç®—æ³•ä¸?
        traditional_weight: ä¼ ç»Ÿç®—æ³•æƒé‡ (æ··åˆç®—æ³•ä¸?
        complexity_weight: å¤æ‚åº¦æƒé‡?(æ··åˆç®—æ³•ä¸?
        
    Returns:
        é‡è¦åº¦åˆ†æç»“æ?    """
    print(f"æ­£åœ¨è®¡ç®—å‡½æ•°é‡è¦åº?.. ä½¿ç”¨ç®—æ³•: {algorithm}")
    
    # æ ¹æ®ç®—æ³•ç±»å‹é€‰æ‹©è®¡ç®—æ–¹æ³•
    if algorithm == "pagerank":
        return _calculate_pagerank_importance(function_map, direct_calls, transitive_calls, transitive_paths)
    elif algorithm == "traditional":
        return _calculate_traditional_importance(function_map, direct_calls, transitive_calls, transitive_paths)
    elif algorithm == "hybrid":
        return _calculate_hybrid_importance(function_map, direct_calls, transitive_calls, transitive_paths,
                                          pagerank_weight, traditional_weight, complexity_weight)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ç®—æ³•ç±»å‹: {algorithm}")


def _calculate_traditional_importance(function_map: Dict, direct_calls: Dict, transitive_calls: Dict, transitive_paths: Dict) -> Dict:
    """ä¼ ç»Ÿçš„å¤šç»´åº¦ç»Ÿè®¡ç®—æ³•"""
    print("ä½¿ç”¨ä¼ ç»Ÿç»Ÿè®¡ç®—æ³•...")
    
    importance_scores = {}
    
    # ç»Ÿè®¡æ¯ä¸ªå‡½æ•°è¢«è°ƒç”¨çš„æ¬¡æ•°ï¼ˆå…¥åº¦ï¼‰
    incoming_calls = defaultdict(int)
    for targets in direct_calls.values():
        for target in targets:
            incoming_calls[target] += 1
    
    # ç»Ÿè®¡æ¯ä¸ªå‡½æ•°åœ¨ä¼ é€’è°ƒç”¨ä¸­è¢«å½±å“çš„æ¬¡æ•°
    transitive_impact = defaultdict(int)
    for targets in transitive_calls.values():
        for target in targets:
            transitive_impact[target] += 1
    
    for func_name in function_map.keys():
        # 1. ç›´æ¥è°ƒç”¨æƒé‡ (DCW) - è¯¥å‡½æ•°è°ƒç”¨å…¶ä»–å‡½æ•°çš„æ•°é‡
        direct_call_weight = len(direct_calls.get(func_name, set()))
        
        # 2. ä¼ é€’è°ƒç”¨æƒé‡?(TCW) - è¯¥å‡½æ•°é€šè¿‡ä¼ é€’è°ƒç”¨å½±å“çš„å…¶ä»–å‡½æ•°æ•°é‡
        transitive_call_weight = len(transitive_calls.get(func_name, set()))
        
        # 3. è°ƒç”¨æ·±åº¦å½±å“ (DI) - è€ƒè™‘è°ƒç”¨é“¾çš„æ·±åº¦ï¼Œæ·±åº¦è¶Šæ·±å½±å“è¶Šå¤?        depth_impact = 0
        max_depth = 0
        for path in transitive_paths.values():
            if func_name in path:
                depth = len(path)
                max_depth = max(max_depth, depth)
                # æ·±åº¦å½±å“ï¼šæ·±åº¦è¶Šæ·±ï¼Œå½±å“è¶Šå¤§ï¼Œä½¿ç”¨å¯¹æ•°å¢é•?                depth_impact += math.log(depth + 1, 2)
        
        # 4. æ¢çº½æ•ˆåº” (HE) - å¦‚æœå‡½æ•°æ—¢æ˜¯è°ƒç”¨è€…åˆæ˜¯è¢«è°ƒç”¨è€…ï¼Œè¯´æ˜å®ƒæ˜¯æ¢çº½
        hub_effect = 0
        if func_name in direct_calls and incoming_calls[func_name] > 0:
            # æ¢çº½æ•ˆåº”ï¼šæ—¢æ˜¯è°ƒç”¨è€…åˆæ˜¯è¢«è°ƒç”¨è€…ï¼Œæƒé‡æ›´é«˜
            hub_effect = min(direct_call_weight, incoming_calls[func_name]) * 0.5
        
        # 5. è¢«è°ƒç”¨é¢‘ç?(ICF) - è¯¥å‡½æ•°è¢«å…¶ä»–å‡½æ•°è°ƒç”¨çš„æ¬¡æ•?        incoming_call_frequency = incoming_calls[func_name]
        
        # 6. å¤æ‚åº¦è°ƒæ•´å› å­?(CA) - åŸºäºå‡½æ•°çš„å¤æ‚åº¦è¿›è¡Œè°ƒæ•´
        func_info = function_map[func_name]
        complexity_score = func_info["complexity"]["semantic_complexity"]["complexity_score"]
        lines_of_code = func_info["complexity"]["semantic_complexity"]["lines_of_code"]
        cyclomatic_complexity = func_info["complexity"]["semantic_complexity"]["cyclomatic_complexity"]
        
        # å¤æ‚åº¦è°ƒæ•´ï¼šå¤æ‚åº¦è¶Šé«˜ï¼Œé‡è¦åº¦è¶Šé«˜ï¼Œä½†è¿‡é«˜çš„å¤æ‚åº¦å¯èƒ½è¡¨ç¤ºä»£ç è´¨é‡å·®
        complexity_adjustment = 1.0
        if complexity_score > 0:
            # ä½¿ç”¨å¯¹æ•°è°ƒæ•´ï¼Œé¿å…è¿‡é«˜å¤æ‚åº¦è¿‡åº¦å½±å“
            complexity_adjustment = 1.0 + math.log(complexity_score + 1, 10) * 0.3
        
        # 7. ç‰¹æ®Šæƒ…å†µçš„é¢å¤–æƒé‡?        special_weight = 0
        
        # å¦‚æœå‡½æ•°åªè°ƒç”¨äº†å¾ˆå°‘çš„å‡½æ•°ï¼Œä½†è¢«å¾ˆå¤šå‡½æ•°è°ƒç”¨ï¼Œè¯´æ˜å®ƒæ˜¯é‡è¦çš„åŸºç¡€å‡½æ•°
        if direct_call_weight <= 2 and incoming_call_frequency >= 5:
            special_weight = incoming_call_frequency * 0.2
        
        # å¦‚æœå‡½æ•°è°ƒç”¨äº†å¾ˆå¤šå…¶ä»–å‡½æ•°ï¼Œè¯´æ˜å®ƒæ˜¯é‡è¦çš„åè°ƒå‡½æ•?        if direct_call_weight >= 5:
            special_weight += direct_call_weight * 0.1
        
        # 8. è®¡ç®—æœ€ç»ˆé‡è¦åº¦
        base_importance = (
            direct_call_weight * 1.0 +           # ç›´æ¥è°ƒç”¨æƒé‡
            transitive_call_weight * 0.8 +       # ä¼ é€’è°ƒç”¨æƒé‡ï¼ˆç¨å¾®é™ä½ï¼?            depth_impact * 0.6 +                 # æ·±åº¦å½±å“
            hub_effect * 1.2 +                   # æ¢çº½æ•ˆåº”ï¼ˆæƒé‡æœ€é«˜ï¼‰
            incoming_call_frequency * 0.7 +      # è¢«è°ƒç”¨é¢‘ç?            special_weight                        # ç‰¹æ®Šæƒ…å†µæƒé‡
        )
        
        final_importance = base_importance * complexity_adjustment
        
        # 9. è®¡ç®—é‡è¦åº¦ç­‰çº?        importance_level = _get_importance_level(final_importance)
        
        importance_scores[func_name] = {
            "total_score": round(final_importance, 2),
            "importance_level": importance_level,
            "breakdown": {
                "direct_call_weight": direct_call_weight,
                "transitive_call_weight": transitive_call_weight,
                "depth_impact": round(depth_impact, 2),
                "hub_effect": round(hub_effect, 2),
                "incoming_call_frequency": incoming_call_frequency,
                "special_weight": round(special_weight, 2),
                "complexity_adjustment": round(complexity_adjustment, 2)
            },
            "metrics": {
                "max_call_depth": max_depth,
                "total_influence_scope": direct_call_weight + transitive_call_weight,
                "is_hub": func_name in direct_calls and incoming_calls[func_name] > 0,
                "is_leaf": func_name not in direct_calls and incoming_calls[func_name] > 0,
                "is_coordinator": direct_call_weight >= 5,
                "is_foundation": direct_call_weight <= 2 and incoming_call_frequency >= 5
            }
        }
    
    # æŒ‰é‡è¦åº¦æ’åº
    sorted_importance = sorted(
        importance_scores.items(), 
        key=lambda x: x[1]["total_score"], 
        reverse=True
    )
    
    # æ·»åŠ æ’åä¿¡æ¯
    for rank, (func_name, score_info) in enumerate(sorted_importance, 1):
        score_info["rank"] = rank
    
    return {
        "algorithm": "traditional",
        "scores": importance_scores,
        "top_functions": [
            {
                "function_name": func_name,
                "total_score": score_info["total_score"],
                "importance_level": score_info["importance_level"],
                "rank": score_info["rank"]
            }
            for func_name, score_info in sorted_importance[:20]  # å‰?0å?        ],
        "importance_distribution": _calculate_importance_distribution(importance_scores)
    }


def _calculate_pagerank_importance(function_map: Dict, direct_calls: Dict, transitive_calls: Dict, transitive_paths: Dict) -> Dict:
    """åŸºäºPageRankçš„å›¾ç®—æ³•"""
    print("ä½¿ç”¨PageRankç®—æ³•...")
    
    if not NETWORKX_AVAILABLE:
        print("è­¦å‘Š: NetworkXä¸å¯ç”¨ï¼Œå›é€€åˆ°ä¼ ç»Ÿç®—æ³?)
        return _calculate_traditional_importance(function_map, direct_calls, transitive_calls, transitive_paths)
    
    # æ„å»ºè°ƒç”¨å›?    G = _build_call_graph(function_map, direct_calls)
    
    if G.number_of_nodes() == 0:
        print("è­¦å‘Š: å›¾ä¸­æ²¡æœ‰èŠ‚ç‚¹ï¼Œå›é€€åˆ°ä¼ ç»Ÿç®—æ³?)
        return _calculate_traditional_importance(function_map, direct_calls, transitive_calls, transitive_paths)
    
    # è®¡ç®—PageRankåˆ†æ•°
    try:
        pagerank_scores = nx.pagerank(G, weight='weight', max_iter=1000, tol=1e-06)
    except Exception as e:
        print(f"PageRankè®¡ç®—å¤±è´¥: {e}ï¼Œå›é€€åˆ°ä¼ ç»Ÿç®—æ³?)
        return _calculate_traditional_importance(function_map, direct_calls, transitive_calls, transitive_paths)
    
    # è®¡ç®—å¤æ‚åº¦è°ƒæ•´å› å­?    complexity_adjustments = {}
    for func_name, func_info in function_map.items():
        complexity_score = func_info["complexity"]["semantic_complexity"]["complexity_score"]
        if complexity_score > 0:
            complexity_adjustments[func_name] = 1.0 + math.log(complexity_score + 1, 10) * 0.3
        else:
            complexity_adjustments[func_name] = 1.0
    
    # è®¡ç®—æœ€ç»ˆé‡è¦åº¦åˆ†æ•°
    importance_scores = {}
    for func_name in function_map.keys():
        pagerank_score = pagerank_scores.get(func_name, 0.0)
        complexity_adj = complexity_adjustments.get(func_name, 1.0)
        
        # æœ€ç»ˆåˆ†æ•?= PageRankåˆ†æ•° * å¤æ‚åº¦è°ƒæ•?        final_score = pagerank_score * complexity_adj * 1000  # æ”¾å¤§åˆ°åˆç†èŒƒå›?        
        importance_level = _get_importance_level(final_score)
        
        importance_scores[func_name] = {
            "total_score": round(final_score, 2),
            "importance_level": importance_level,
            "breakdown": {
                "pagerank_score": round(pagerank_score, 6),
                "complexity_adjustment": round(complexity_adj, 2)
            },
            "metrics": {
                "is_hub": func_name in direct_calls and len(direct_calls[func_name]) > 0,
                "out_degree": len(direct_calls.get(func_name, set())),
                "in_degree": sum(1 for targets in direct_calls.values() if func_name in targets)
            }
        }
    
    # æŒ‰é‡è¦åº¦æ’åº
    sorted_importance = sorted(
        importance_scores.items(), 
        key=lambda x: x[1]["total_score"], 
        reverse=True
    )
    
    # æ·»åŠ æ’åä¿¡æ¯
    for rank, (func_name, score_info) in enumerate(sorted_importance, 1):
        score_info["rank"] = rank
    
    return {
        "algorithm": "pagerank",
        "scores": importance_scores,
        "top_functions": [
            {
                "function_name": func_name,
                "total_score": score_info["total_score"],
                "importance_level": score_info["importance_level"],
                "rank": score_info["rank"]
            }
            for func_name, score_info in sorted_importance[:20]
        ],
        "importance_distribution": _calculate_importance_distribution(importance_scores),
        "graph_stats": {
            "total_nodes": G.number_of_nodes(),
            "total_edges": G.number_of_edges(),
            "is_connected": nx.is_weakly_connected(G) if G.number_of_nodes() > 0 else False
        }
    }


def _calculate_hybrid_importance(function_map: Dict, direct_calls: Dict, transitive_calls: Dict, transitive_paths: Dict,
                               pagerank_weight: float, traditional_weight: float, complexity_weight: float) -> Dict:
    """æ··åˆç®—æ³•ï¼šç»“åˆPageRankå’Œä¼ ç»Ÿç®—æ³?""
    print(f"ä½¿ç”¨æ··åˆç®—æ³•... PageRankæƒé‡: {pagerank_weight}, ä¼ ç»Ÿæƒé‡: {traditional_weight}, å¤æ‚åº¦æƒé‡? {complexity_weight}")
    
    # è®¡ç®—ä¼ ç»Ÿç®—æ³•åˆ†æ•°
    traditional_result = _calculate_traditional_importance(function_map, direct_calls, transitive_calls, transitive_paths)
    if traditional_result is None:
        print("è­¦å‘Š: ä¼ ç»Ÿç®—æ³•è®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿç®—æ³?)
        return _calculate_traditional_importance(function_map, direct_calls, transitive_calls, transitive_paths)
    traditional_scores = traditional_result["scores"]
    
    # è®¡ç®—PageRankåˆ†æ•°
    pagerank_result = _calculate_pagerank_importance(function_map, direct_calls, transitive_calls, transitive_paths)
    if pagerank_result is None:
        print("è­¦å‘Š: PageRankç®—æ³•è®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿç®—æ³?)
        return _calculate_traditional_importance(function_map, direct_calls, transitive_calls, transitive_paths)
    pagerank_scores = pagerank_result["scores"]
    
    # å½’ä¸€åŒ–åˆ†æ•°åˆ°ç›¸åŒèŒƒå›´
    traditional_max = max(score["total_score"] for score in traditional_scores.values()) if traditional_scores else 1
    pagerank_max = max(score["total_score"] for score in pagerank_scores.values()) if pagerank_scores else 1
    
    # è®¡ç®—æ··åˆåˆ†æ•°
    importance_scores = {}
    for func_name in function_map.keys():
        # å½’ä¸€åŒ–åˆ†æ•?        norm_traditional = (traditional_scores[func_name]["total_score"] / traditional_max) if traditional_max > 0 else 0
        norm_pagerank = (pagerank_scores[func_name]["total_score"] / pagerank_max) if pagerank_max > 0 else 0
        
        # è·å–å¤æ‚åº¦è°ƒæ•?        complexity_adj = traditional_scores[func_name]["breakdown"]["complexity_adjustment"]
        
        # æ··åˆåˆ†æ•°
        hybrid_score = (
            pagerank_weight * norm_pagerank * 100 +
            traditional_weight * norm_traditional * 100 +
            complexity_weight * (complexity_adj - 1.0) * 50
        )
        
        importance_level = _get_importance_level(hybrid_score)
        
        importance_scores[func_name] = {
            "total_score": round(hybrid_score, 2),
            "importance_level": importance_level,
            "breakdown": {
                "pagerank_score": round(norm_pagerank * 100, 2),
                "traditional_score": round(norm_traditional * 100, 2),
                "complexity_adjustment": round(complexity_adj, 2),
                "pagerank_weight": pagerank_weight,
                "traditional_weight": traditional_weight,
                "complexity_weight": complexity_weight
            },
            "metrics": {
                **traditional_scores[func_name]["metrics"],
                **pagerank_scores[func_name]["metrics"]
            }
        }
    
    # æŒ‰é‡è¦åº¦æ’åº
    sorted_importance = sorted(
        importance_scores.items(), 
        key=lambda x: x[1]["total_score"], 
        reverse=True
    )
    
    # æ·»åŠ æ’åä¿¡æ¯
    for rank, (func_name, score_info) in enumerate(sorted_importance, 1):
        score_info["rank"] = rank
    
    return {
        "algorithm": "hybrid",
        "scores": importance_scores,
        "top_functions": [
            {
                "function_name": func_name,
                "total_score": score_info["total_score"],
                "importance_level": score_info["importance_level"],
                "rank": score_info["rank"]
            }
            for func_name, score_info in sorted_importance[:20]
        ],
        "importance_distribution": _calculate_importance_distribution(importance_scores),
        "algorithm_weights": {
            "pagerank_weight": pagerank_weight,
            "traditional_weight": traditional_weight,
            "complexity_weight": complexity_weight
        }
    }


def _build_call_graph(function_map: Dict, direct_calls: Dict) -> 'nx.DiGraph':
    """æ„å»ºè°ƒç”¨å›?""
    G = nx.DiGraph()
    
    # æ·»åŠ æ‰€æœ‰å‡½æ•°ä½œä¸ºèŠ‚ç‚?    for func_name in function_map.keys():
        G.add_node(func_name)
    
    # æ·»åŠ è°ƒç”¨å…³ç³»ä½œä¸ºè¾?    for caller, callees in direct_calls.items():
        for callee in callees:
            if callee in function_map:  # åªæ·»åŠ å›¾ä¸­å­˜åœ¨çš„å‡½æ•°
                G.add_edge(caller, callee, weight=1.0)
    
    return G


def _get_importance_level(score: float) -> str:
    """
    æ ¹æ®åˆ†æ•°è·å–é‡è¦åº¦ç­‰çº?    
    Args:
        score: é‡è¦åº¦åˆ†æ•?        
    Returns:
        é‡è¦åº¦ç­‰çº?    """
    if score >= IMPORTANCE_THRESHOLDS["Critical"]:
        return "Critical"
    elif score >= IMPORTANCE_THRESHOLDS["High"]:
        return "High"
    elif score >= IMPORTANCE_THRESHOLDS["Medium"]:
        return "Medium"
    elif score >= IMPORTANCE_THRESHOLDS["Low"]:
        return "Low"
    else:
        return "Minimal"


def _calculate_importance_distribution(importance_scores: Dict) -> Dict:
    """
    è®¡ç®—é‡è¦åº¦åˆ†å¸?    
    Args:
        importance_scores: é‡è¦åº¦åˆ†æ•°å­—å…?        
    Returns:
        é‡è¦åº¦åˆ†å¸ƒç»Ÿè®?    """
    distribution = {
        "Critical": 0,
        "High": 0,
        "Medium": 0,
        "Low": 0,
        "Minimal": 0
    }
    
    for score_info in importance_scores.values():
        level = score_info["importance_level"]
        if level in distribution:
            distribution[level] += 1
    
    return distribution


def update_function_importance(all_functions: List[Dict], importance_scores: Dict) -> None:
    """
    æ›´æ–°æ‰€æœ‰å‡½æ•°çš„é‡è¦åº¦ä¿¡æ?    
    Args:
        all_functions: æ‰€æœ‰å‡½æ•°åˆ—è¡?        importance_scores: é‡è¦åº¦åˆ†æ•°å­—å…?    """
    print("  æ›´æ–°å‡½æ•°é‡è¦åº¦ä¿¡æ?..")
    
    scores_dict = importance_scores.get('scores', {})
    
    for func in all_functions:
        func_name = func["basic_info"]["function_name"]
        # ç¡®ä¿func_nameæ˜¯å­—ç¬¦ä¸²ç±»å‹
        if isinstance(func_name, bytes):
            func_name = func_name.decode('utf-8')
        if func_name in scores_dict:
            func["importance"] = scores_dict[func_name]
        else:
            func["importance"] = {
                "status": "calculated",
                "total_score": 0,
                "importance_level": "Minimal",
                "breakdown": {
                    "direct_call_weight": 0,
                    "transitive_call_weight": 0,
                    "depth_impact": 0,
                    "hub_effect": 0,
                    "incoming_call_frequency": 0,
                    "special_weight": 0,
                    "complexity_adjustment": 1.0
                },
                "metrics": {
                    "is_hub": False,
                    "is_leaf": False,
                    "is_coordinator": False,
                    "is_foundation": False
                }
            }


def analyze_importance_trends(importance_scores: Dict) -> Dict:
    """
    åˆ†æé‡è¦åº¦è¶‹åŠ?    
    Args:
        importance_scores: é‡è¦åº¦åˆ†æ•°å­—å…?        
    Returns:
        é‡è¦åº¦è¶‹åŠ¿åˆ†æç»“æ?    """
    scores_dict = importance_scores.get('scores', {})
    
    if not scores_dict:
        return {}
    
    # æŒ‰åˆ†æ•°åˆ†ç»?    score_groups = {
        "Critical": [],
        "High": [],
        "Medium": [],
        "Low": [],
        "Minimal": []
    }
    
    for func_name, score_info in scores_dict.items():
        level = score_info["importance_level"]
        score_groups[level].append({
            "function_name": func_name,
            "score": score_info["total_score"]
        })
    
    # è®¡ç®—æ¯ä¸ªç­‰çº§çš„ç»Ÿè®¡ä¿¡æ?    trends = {}
    for level, functions in score_groups.items():
        if functions:
            scores = [f["score"] for f in functions]
            trends[level] = {
                "count": len(functions),
                "avg_score": sum(scores) / len(scores),
                "max_score": max(scores),
                "min_score": min(scores),
                "top_functions": sorted(functions, key=lambda x: x["score"], reverse=True)[:5]
            }
        else:
            trends[level] = {
                "count": 0,
                "avg_score": 0,
                "max_score": 0,
                "min_score": 0,
                "top_functions": []
            }
    
    return trends


def compare_algorithms(function_map: Dict, direct_calls: Dict, transitive_calls: Dict, transitive_paths: Dict) -> Dict:
    """
    æ¯”è¾ƒä¸åŒç®—æ³•çš„é‡è¦åº¦è®¡ç®—ç»“æœ
    
    Args:
        function_map: å‡½æ•°ååˆ°å‡½æ•°ä¿¡æ¯çš„æ˜ å°?        direct_calls: ç›´æ¥è°ƒç”¨å…³ç³»
        transitive_calls: ä¼ é€’è°ƒç”¨å…³ç³?        transitive_paths: ä¼ é€’è°ƒç”¨è·¯å¾?        
    Returns:
        ç®—æ³•æ¯”è¾ƒç»“æœ
    """
    print("æ¯”è¾ƒä¸åŒç®—æ³•çš„é‡è¦åº¦è®¡ç®—ç»“æœ...")
    
    algorithms = ["traditional", "pagerank", "hybrid"]
    results = {}
    
    for algorithm in algorithms:
        print(f"è®¡ç®— {algorithm} ç®—æ³•...")
        if algorithm == "hybrid":
            result = calculate_function_importance(
                function_map, direct_calls, transitive_calls, transitive_paths,
                algorithm=algorithm, pagerank_weight=0.4, traditional_weight=0.4, complexity_weight=0.2
            )
        else:
            result = calculate_function_importance(
                function_map, direct_calls, transitive_calls, transitive_paths,
                algorithm=algorithm
            )
        results[algorithm] = result
    
    # åˆ†æç®—æ³•å·®å¼‚
    comparison = {
        "algorithms": algorithms,
        "results": results,
        "top_functions_comparison": {},
        "correlation_analysis": {},
        "algorithm_characteristics": {
            "traditional": {
                "description": "åŸºäºç»Ÿè®¡çš„å¤šç»´åº¦ç®—æ³•",
                "strengths": ["è€ƒè™‘å¤æ‚åº?, "å¯è§£é‡Šæ€§å¼º", "è®¡ç®—ç®€å?],
                "weaknesses": ["å¿½ç•¥å…¨å±€å½±å“", "æƒé‡ä¸»è§‚", "ç¼ºä¹ä¼ é€’æ€§åˆ†æ?]
            },
            "pagerank": {
                "description": "åŸºäºå›¾ç»“æ„çš„å…¨å±€é‡è¦æ€§ç®—æ³?,
                "strengths": ["å…¨å±€è§†è§’", "ä¼ é€’æ€§åˆ†æ?, "æ•°å­¦åŸºç¡€æ‰å®"],
                "weaknesses": ["å¿½ç•¥ä»£ç å¤æ‚åº?, "å¯¹å­¤ç«‹èŠ‚ç‚¹ä¸å‹å¥½", "éœ€è¦å®Œæ•´å›¾ç»“æ„"]
            },
            "hybrid": {
                "description": "ç»“åˆPageRankå’Œä¼ ç»Ÿç®—æ³•çš„æ··åˆæ–¹æ³•",
                "strengths": ["å…¼é¡¾å…¨å±€å’Œå±€éƒ?, "å¹³è¡¡å¤šç§å› ç´ ", "å¯è°ƒèŠ‚æƒé‡?],
                "weaknesses": ["è®¡ç®—å¤æ‚åº¦é«˜", "å‚æ•°è°ƒä¼˜å¤æ‚", "ç»“æœè§£é‡Šæ€§é™ä½?]
            }
        }
    }
    
    # æ¯”è¾ƒå‰?0åå‡½æ•?    for algorithm in algorithms:
        top_functions = results[algorithm]["top_functions"][:10]
        comparison["top_functions_comparison"][algorithm] = [
            {
                "function_name": func["function_name"],
                "score": func["total_score"],
                "rank": func["rank"]
            }
            for func in top_functions
        ]
    
    # è®¡ç®—ç®—æ³•é—´çš„ç›¸å…³æ€?    if len(algorithms) >= 2:
        for i, alg1 in enumerate(algorithms):
            for alg2 in algorithms[i+1:]:
                scores1 = {func["function_name"] if isinstance(func["function_name"], str) else func["function_name"].decode('utf-8'): func["total_score"] 
                          for func in results[alg1]["top_functions"]}
                scores2 = {func["function_name"] if isinstance(func["function_name"], str) else func["function_name"].decode('utf-8'): func["total_score"] 
                          for func in results[alg2]["top_functions"]}
                
                # è®¡ç®—å…±åŒå‡½æ•°çš„åˆ†æ•°ç›¸å…³æ€?                common_functions = set(scores1.keys()) & set(scores2.keys())
                if len(common_functions) > 1:
                    scores1_list = [scores1[func] for func in common_functions]
                    scores2_list = [scores2[func] for func in common_functions]
                    
                    correlation = np.corrcoef(scores1_list, scores2_list)[0, 1] if len(scores1_list) > 1 else 0
                    comparison["correlation_analysis"][f"{alg1}_vs_{alg2}"] = {
                        "correlation": round(correlation, 3),
                        "common_functions": len(common_functions)
                    }
    
    return comparison


def get_importance_summary(importance_scores: Dict) -> Dict:
    """
    è·å–é‡è¦åº¦åˆ†ææ‘˜è¦?    
    Args:
        importance_scores: é‡è¦åº¦åˆ†æ•°å­—å…?        
    Returns:
        é‡è¦åº¦åˆ†ææ‘˜è¦?    """
    scores_dict = importance_scores.get('scores', {})
    distribution = importance_scores.get('importance_distribution', {})
    top_functions = importance_scores.get('top_functions', [])
    
    total_functions = len(scores_dict)
    critical_functions = distribution.get('Critical', 0)
    high_functions = distribution.get('High', 0)
    
    # è®¡ç®—å…³é”®å‡½æ•°æ¯”ä¾‹
    critical_ratio = critical_functions / total_functions if total_functions > 0 else 0
    high_importance_ratio = (critical_functions + high_functions) / total_functions if total_functions > 0 else 0
    
    return {
        "total_functions": total_functions,
        "critical_functions": critical_functions,
        "high_importance_functions": critical_functions + high_functions,
        "critical_ratio": round(critical_ratio * 100, 2),
        "high_importance_ratio": round(high_importance_ratio * 100, 2),
        "top_5_functions": top_functions[:5],
        "importance_distribution": distribution,
        "analysis_quality": "high" if total_functions > 10 else "low"
    }

